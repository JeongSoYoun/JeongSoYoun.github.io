{"expireTime":9007200906040739000,"key":"transformer-remark-markdown-html-ast-b2978492a17f2a9547b4227454bef09c-gatsby-remark-katexgatsby-remark-imagesgatsby-remark-images-medium-zoomgatsby-remark-responsive-iframegatsby-remark-prismjsgatsby-remark-copy-linked-filesgatsby-remark-smartypantsgatsby-remark-autolink-headersgatsby-remark-emoji-","val":{"type":"root","children":[{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{"id":"introduction","style":"position:relative;"},"children":[{"type":"element","tagName":"a","properties":{"href":"#introduction","aria-label":"introduction permalink","class":"anchor before"},"children":[{"type":"raw","value":"<svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg>"}]},{"type":"text","value":"Introduction","position":{"start":{"line":2,"column":7,"offset":7},"end":{"line":2,"column":19,"offset":19}}}],"position":{"start":{"line":2,"column":3,"offset":3},"end":{"line":2,"column":19,"offset":19}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"From Transformer model with ","position":{"start":{"line":4,"column":3,"offset":24},"end":{"line":4,"column":31,"offset":52}}},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"attention","position":{"start":{"line":4,"column":32,"offset":53},"end":{"line":4,"column":41,"offset":62}}}],"position":{"start":{"line":4,"column":31,"offset":52},"end":{"line":4,"column":42,"offset":63}}},{"type":"text","value":" , we have seen that NLP task can be done without RNN architecture, which has brought phenomenal development for NLP. This model has become fundamental architecture for NLP models such as BERT and GPT, which are two top tier NLP model nowadays. Today, I am going to talk about ","position":{"start":{"line":4,"column":42,"offset":63},"end":{"line":4,"column":319,"offset":340}}},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"GPT","position":{"start":{"line":4,"column":322,"offset":343},"end":{"line":4,"column":325,"offset":346}}}],"position":{"start":{"line":4,"column":321,"offset":342},"end":{"line":4,"column":326,"offset":347}}}],"position":{"start":{"line":4,"column":319,"offset":340},"end":{"line":4,"column":328,"offset":349}}},{"type":"text","value":" model.","position":{"start":{"line":4,"column":328,"offset":349},"end":{"line":4,"column":335,"offset":356}}}],"position":{"start":{"line":4,"column":3,"offset":24},"end":{"line":4,"column":335,"offset":356}}},{"type":"text","value":"\n"}],"position":{"start":{"line":2,"column":1,"offset":1},"end":{"line":4,"column":335,"offset":356}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"raw","value":"<br />","position":{"start":{"line":6,"column":1,"offset":358},"end":{"line":6,"column":7,"offset":364}}},{"type":"text","value":" ","position":{"start":{"line":6,"column":7,"offset":364},"end":{"line":6,"column":8,"offset":365}}},{"type":"text","value":" ","position":{"start":{"line":6,"column":8,"offset":365},"end":{"line":6,"column":14,"offset":371}}},{"type":"text","value":" ","position":{"start":{"line":6,"column":14,"offset":371},"end":{"line":6,"column":20,"offset":377}}},{"type":"text","value":" ","position":{"start":{"line":6,"column":20,"offset":377},"end":{"line":6,"column":26,"offset":383}}},{"type":"text","value":" ","position":{"start":{"line":6,"column":26,"offset":383},"end":{"line":6,"column":32,"offset":389}}},{"type":"text","value":" ","position":{"start":{"line":6,"column":32,"offset":389},"end":{"line":6,"column":38,"offset":395}}},{"type":"text","value":" GPT, ","position":{"start":{"line":6,"column":38,"offset":395},"end":{"line":6,"column":44,"offset":401}}},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"Generative Pre Training","position":{"start":{"line":6,"column":45,"offset":402},"end":{"line":6,"column":68,"offset":425}}}],"position":{"start":{"line":6,"column":44,"offset":401},"end":{"line":6,"column":69,"offset":426}}},{"type":"text","value":", is a language model developed by ","position":{"start":{"line":6,"column":69,"offset":426},"end":{"line":6,"column":104,"offset":461}}},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"Open AI","position":{"start":{"line":6,"column":106,"offset":463},"end":{"line":6,"column":113,"offset":470}}}],"position":{"start":{"line":6,"column":104,"offset":461},"end":{"line":6,"column":115,"offset":472}}},{"type":"text","value":" with combination of generative pre-training and discriminative fine-tuning process. The goal of GPT is making a general language model(pre-training) that can be adapted to lots of tasks with small adjustment of the model(fine-tuning).","position":{"start":{"line":6,"column":115,"offset":472},"end":{"line":6,"column":350,"offset":707}}}],"position":{"start":{"line":6,"column":1,"offset":358},"end":{"line":6,"column":350,"offset":707}}},{"type":"text","value":"\n"},{"type":"raw","value":"<br />","position":{"start":{"line":8,"column":1,"offset":709},"end":{"line":8,"column":7,"offset":715}}},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{"id":"trainig-process","style":"position:relative;"},"children":[{"type":"element","tagName":"a","properties":{"href":"#trainig-process","aria-label":"trainig process permalink","class":"anchor before"},"children":[{"type":"raw","value":"<svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg>"}]},{"type":"text","value":"Trainig Process","position":{"start":{"line":10,"column":7,"offset":723},"end":{"line":10,"column":22,"offset":738}}}],"position":{"start":{"line":10,"column":3,"offset":719},"end":{"line":10,"column":22,"offset":738}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"From pre-training to fine-tuning","position":{"start":{"line":12,"column":3,"offset":743},"end":{"line":12,"column":35,"offset":775}}}],"position":{"start":{"line":12,"column":3,"offset":743},"end":{"line":12,"column":35,"offset":775}}},{"type":"text","value":"\n"}],"position":{"start":{"line":10,"column":1,"offset":717},"end":{"line":12,"column":35,"offset":775}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"raw","value":"<br />","position":{"start":{"line":14,"column":1,"offset":777},"end":{"line":14,"column":7,"offset":783}}},{"type":"text","value":" ","position":{"start":{"line":14,"column":7,"offset":783},"end":{"line":14,"column":8,"offset":784}}},{"type":"text","value":" ","position":{"start":{"line":14,"column":8,"offset":784},"end":{"line":14,"column":14,"offset":790}}},{"type":"text","value":" ","position":{"start":{"line":14,"column":14,"offset":790},"end":{"line":14,"column":20,"offset":796}}},{"type":"text","value":" ","position":{"start":{"line":14,"column":20,"offset":796},"end":{"line":14,"column":26,"offset":802}}},{"type":"text","value":" ","position":{"start":{"line":14,"column":26,"offset":802},"end":{"line":14,"column":32,"offset":808}}},{"type":"text","value":" ","position":{"start":{"line":14,"column":32,"offset":808},"end":{"line":14,"column":38,"offset":814}}},{"type":"text","value":" First, pre-training(unsupervised learning with set of large-corpus of text data) is done to learn the parameters of language model. Since, the goal of unsupervised learning is to initialize the training, the objectives of learning remain same with supervised learning. After pre-training, supervised learning with same parameters that have pre-trained is processed with fine-tuning of some change of input tokens and the weight of the output layer.","position":{"start":{"line":14,"column":38,"offset":814},"end":{"line":14,"column":487,"offset":1263}}}],"position":{"start":{"line":14,"column":1,"offset":777},"end":{"line":14,"column":487,"offset":1263}}},{"type":"text","value":"\n"},{"type":"raw","value":"<br />","position":{"start":{"line":16,"column":1,"offset":1265},"end":{"line":16,"column":7,"offset":1271}}},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{"id":"architecture","style":"position:relative;"},"children":[{"type":"element","tagName":"a","properties":{"href":"#architecture","aria-label":"architecture permalink","class":"anchor before"},"children":[{"type":"raw","value":"<svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg>"}]},{"type":"text","value":"Architecture","position":{"start":{"line":18,"column":7,"offset":1279},"end":{"line":18,"column":19,"offset":1291}}}],"position":{"start":{"line":18,"column":3,"offset":1275},"end":{"line":18,"column":19,"offset":1291}}},{"type":"text","value":"\n"}],"position":{"start":{"line":18,"column":1,"offset":1273},"end":{"line":18,"column":19,"offset":1291}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"raw","value":"<br />","position":{"start":{"line":20,"column":1,"offset":1293},"end":{"line":20,"column":7,"offset":1299}}},{"type":"text","value":" ","position":{"start":{"line":20,"column":7,"offset":1299},"end":{"line":20,"column":8,"offset":1300}}},{"type":"text","value":" ","position":{"start":{"line":20,"column":8,"offset":1300},"end":{"line":20,"column":14,"offset":1306}}},{"type":"text","value":" ","position":{"start":{"line":20,"column":14,"offset":1306},"end":{"line":20,"column":20,"offset":1312}}},{"type":"text","value":" ","position":{"start":{"line":20,"column":20,"offset":1312},"end":{"line":20,"column":26,"offset":1318}}},{"type":"text","value":" ","position":{"start":{"line":20,"column":26,"offset":1318},"end":{"line":20,"column":32,"offset":1324}}},{"type":"text","value":" ","position":{"start":{"line":20,"column":32,"offset":1324},"end":{"line":20,"column":38,"offset":1330}}},{"type":"text","value":" From pre-training to fine-tuning, architecture of GPT is ","position":{"start":{"line":20,"column":38,"offset":1330},"end":{"line":20,"column":96,"offset":1388}}},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"Transformer Model","position":{"start":{"line":20,"column":99,"offset":1391},"end":{"line":20,"column":116,"offset":1408}}}],"position":{"start":{"line":20,"column":98,"offset":1390},"end":{"line":20,"column":117,"offset":1409}}}],"position":{"start":{"line":20,"column":96,"offset":1388},"end":{"line":20,"column":119,"offset":1411}}},{"type":"text","value":". Interesting point is ","position":{"start":{"line":20,"column":119,"offset":1411},"end":{"line":20,"column":142,"offset":1434}}},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"GPT","position":{"start":{"line":20,"column":143,"offset":1435},"end":{"line":20,"column":146,"offset":1438}}}],"position":{"start":{"line":20,"column":142,"offset":1434},"end":{"line":20,"column":147,"offset":1439}}},{"type":"text","value":" only uses ","position":{"start":{"line":20,"column":147,"offset":1439},"end":{"line":20,"column":158,"offset":1450}}},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"Decoder","position":{"start":{"line":20,"column":160,"offset":1452},"end":{"line":20,"column":167,"offset":1459}}}],"position":{"start":{"line":20,"column":158,"offset":1450},"end":{"line":20,"column":169,"offset":1461}}},{"type":"text","value":" layer which has ","position":{"start":{"line":20,"column":169,"offset":1461},"end":{"line":20,"column":186,"offset":1478}}},{"type":"text","value":"_","position":{"start":{"line":20,"column":186,"offset":1478},"end":{"line":20,"column":188,"offset":1480}}},{"type":"text","value":"masked self attention layer","position":{"start":{"line":20,"column":188,"offset":1480},"end":{"line":20,"column":215,"offset":1507}}},{"type":"text","value":"*","position":{"start":{"line":20,"column":215,"offset":1507},"end":{"line":20,"column":217,"offset":1509}}}],"position":{"start":{"line":20,"column":1,"offset":1293},"end":{"line":20,"column":217,"offset":1509}}}],"position":{"start":{"line":1,"column":1,"offset":0},"end":{"line":21,"column":1,"offset":1510}}}}