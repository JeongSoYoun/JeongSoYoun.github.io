{"expireTime":9007200905725718000,"key":"transformer-remark-markdown-ast-efcbdc5eb8054018c668b8ef63c7129b-gatsby-remark-katexgatsby-remark-imagesgatsby-remark-images-medium-zoomgatsby-remark-responsive-iframegatsby-remark-prismjsgatsby-remark-copy-linked-filesgatsby-remark-smartypantsgatsby-remark-autolink-headersgatsby-remark-emoji-","val":{"type":"root","children":[{"type":"paragraph","children":[{"type":"html","value":"<br />","position":{"start":{"line":2,"column":1,"offset":1},"end":{"line":2,"column":7,"offset":7},"indent":[]}},{"type":"html","value":"<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1200px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 52.66666666666667%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAAsTAAALEwEAmpwYAAAA+0lEQVQoz6WRX0/CMBTF+f5fQh/gnSiDESHCg9FgjAlGJeFPhKVra2xj1rK1dm3tcOjCQAKcNGlzkt/tvedW7Amq5LcxxmbnKDgvkdFmXW1Dv2YJ/pKCz5dqmTexWxuwkdrGIaWgWX+eMG6HT8P5IkgSEceJE2NsNnvjnGutx5MpRFgI8Qcn2kaLDxq2a4/TAPDB/aB73b/0Wn670/KvGp5/dl6tX3ghRM65ub1j7odVCxmcWqto9In6DyBwLsIYAIjxO0QIQtTp9l5eR4SQKGJSSkJomqalwLSw29JWSm0duLiqFb6O1I33E6x7FJMvB1ZY1L54/93zgfoGgyp+WM2mC3AAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"google\" title=\"google\" src=\"/static/fbc6dd92a8903039c6d1223bd49971b7/c1b63/google.png\" srcset=\"/static/fbc6dd92a8903039c6d1223bd49971b7/5a46d/google.png 300w,\n/static/fbc6dd92a8903039c6d1223bd49971b7/0a47e/google.png 600w,\n/static/fbc6dd92a8903039c6d1223bd49971b7/c1b63/google.png 1200w\" sizes=\"(max-width: 1200px) 100vw, 1200px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n    </span>","position":{"start":{"line":2,"column":7,"offset":7},"end":{"line":2,"column":63,"offset":63},"indent":[]}},{"type":"html","value":"<br/>","position":{"start":{"line":2,"column":63,"offset":63},"end":{"line":2,"column":68,"offset":68},"indent":[]}},{"type":"html","value":"<br/>","position":{"start":{"line":2,"column":68,"offset":68},"end":{"line":2,"column":73,"offset":73},"indent":[]}}],"position":{"start":{"line":2,"column":1,"offset":1},"end":{"line":2,"column":73,"offset":73},"indent":[]}},{"type":"blockquote","children":[{"type":"heading","depth":3,"children":[{"type":"link","url":"#transformer-model-attention-is-all-you-need","title":null,"children":[],"data":{"hProperties":{"aria-label":"transformer model attention is all you need permalink","class":"anchor before"},"hChildren":[{"type":"raw","value":"<svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg>"}]}},{"type":"emphasis","children":[{"type":"text","value":"Transformer Model: Attention is all you Need","position":{"start":{"line":4,"column":8,"offset":82},"end":{"line":4,"column":52,"offset":126},"indent":[]}}],"position":{"start":{"line":4,"column":7,"offset":81},"end":{"line":4,"column":53,"offset":127},"indent":[]}}],"position":{"start":{"line":4,"column":3,"offset":77},"end":{"line":4,"column":53,"offset":127},"indent":[]},"data":{"id":"transformer-model-attention-is-all-you-need","htmlAttributes":{"id":"transformer-model-attention-is-all-you-need"},"hProperties":{"id":"transformer-model-attention-is-all-you-need","style":"position:relative;"}}}],"position":{"start":{"line":4,"column":1,"offset":75},"end":{"line":4,"column":53,"offset":127},"indent":[]}},{"type":"heading","depth":2,"children":[{"type":"link","url":"#introduction","title":null,"children":[],"data":{"hProperties":{"aria-label":"introduction permalink","class":"anchor before"},"hChildren":[{"type":"raw","value":"<svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg>"}]}},{"type":"text","value":"Introduction","position":{"start":{"line":6,"column":4,"offset":132},"end":{"line":6,"column":16,"offset":144},"indent":[]}}],"position":{"start":{"line":6,"column":1,"offset":129},"end":{"line":6,"column":16,"offset":144},"indent":[]},"data":{"id":"introduction","htmlAttributes":{"id":"introduction"},"hProperties":{"id":"introduction","style":"position:relative;"}}},{"type":"paragraph","children":[{"type":"html","value":"<br />","position":{"start":{"line":8,"column":1,"offset":146},"end":{"line":8,"column":7,"offset":152},"indent":[]}},{"type":"html","value":"<br />","position":{"start":{"line":8,"column":7,"offset":152},"end":{"line":8,"column":13,"offset":158},"indent":[]}},{"type":"text","value":"Transformer model was published by ","position":{"start":{"line":8,"column":13,"offset":158},"end":{"line":8,"column":48,"offset":193},"indent":[]}},{"type":"strong","children":[{"type":"text","value":"Google AI","position":{"start":{"line":8,"column":50,"offset":195},"end":{"line":8,"column":59,"offset":204},"indent":[]}}],"position":{"start":{"line":8,"column":48,"offset":193},"end":{"line":8,"column":61,"offset":206},"indent":[]}},{"type":"text","value":" on 2017, and became fundamental of Natural Language Process Model for the other models such as ","position":{"start":{"line":8,"column":61,"offset":206},"end":{"line":8,"column":157,"offset":302},"indent":[]}},{"type":"emphasis","children":[{"type":"text","value":"BERT","position":{"start":{"line":8,"column":158,"offset":303},"end":{"line":8,"column":162,"offset":307},"indent":[]}}],"position":{"start":{"line":8,"column":157,"offset":302},"end":{"line":8,"column":163,"offset":308},"indent":[]}},{"type":"text","value":" or ","position":{"start":{"line":8,"column":163,"offset":308},"end":{"line":8,"column":167,"offset":312},"indent":[]}},{"type":"emphasis","children":[{"type":"text","value":"GPT","position":{"start":{"line":8,"column":168,"offset":313},"end":{"line":8,"column":171,"offset":316},"indent":[]}}],"position":{"start":{"line":8,"column":167,"offset":312},"end":{"line":8,"column":172,"offset":317},"indent":[]}},{"type":"text","value":". What makes Transformer model attractive is, this model never uses ","position":{"start":{"line":8,"column":172,"offset":317},"end":{"line":8,"column":240,"offset":385},"indent":[]}},{"type":"strong","children":[{"type":"text","value":"RNN","position":{"start":{"line":8,"column":242,"offset":387},"end":{"line":8,"column":245,"offset":390},"indent":[]}}],"position":{"start":{"line":8,"column":240,"offset":385},"end":{"line":8,"column":247,"offset":392},"indent":[]}},{"type":"text","value":", one of the greatest sequence model, architecture. It only uses ","position":{"start":{"line":8,"column":247,"offset":392},"end":{"line":8,"column":312,"offset":457},"indent":[]}},{"type":"strong","children":[{"type":"text","value":"Attention","position":{"start":{"line":8,"column":314,"offset":459},"end":{"line":8,"column":323,"offset":468},"indent":[]}}],"position":{"start":{"line":8,"column":312,"offset":457},"end":{"line":8,"column":325,"offset":470},"indent":[]}},{"type":"text","value":".","position":{"start":{"line":8,"column":325,"offset":470},"end":{"line":8,"column":326,"offset":471},"indent":[]}}],"position":{"start":{"line":8,"column":1,"offset":146},"end":{"line":8,"column":326,"offset":471},"indent":[]}},{"type":"paragraph","children":[{"type":"html","value":"<br />","position":{"start":{"line":10,"column":1,"offset":473},"end":{"line":10,"column":7,"offset":479},"indent":[]}},{"type":"text","value":"Our language has some meaningful connection between words, which we called ","position":{"start":{"line":10,"column":7,"offset":479},"end":{"line":10,"column":82,"offset":554},"indent":[]}},{"type":"emphasis","children":[{"type":"text","value":"context","position":{"start":{"line":10,"column":83,"offset":555},"end":{"line":10,"column":90,"offset":562},"indent":[]}}],"position":{"start":{"line":10,"column":82,"offset":554},"end":{"line":10,"column":91,"offset":563},"indent":[]}},{"type":"text","value":".\nFor human, we can easily guess what ","position":{"start":{"line":10,"column":91,"offset":563},"end":{"line":11,"column":37,"offset":601},"indent":[1]}},{"type":"emphasis","children":[{"type":"text","value":"it","position":{"start":{"line":11,"column":38,"offset":602},"end":{"line":11,"column":40,"offset":604},"indent":[]}}],"position":{"start":{"line":11,"column":37,"offset":601},"end":{"line":11,"column":41,"offset":605},"indent":[]}},{"type":"text","value":" stands for, but for machine learning points of view, it is hard to train what ","position":{"start":{"line":11,"column":41,"offset":605},"end":{"line":11,"column":120,"offset":684},"indent":[]}},{"type":"emphasis","children":[{"type":"text","value":"it","position":{"start":{"line":11,"column":121,"offset":685},"end":{"line":11,"column":123,"offset":687},"indent":[]}}],"position":{"start":{"line":11,"column":120,"offset":684},"end":{"line":11,"column":124,"offset":688},"indent":[]}},{"type":"text","value":" means in the sentence. The biggest disadvantage of RNN is, this model only depends only short-term memory, so if our input text data set is large, performance of RNN is decreasing. To cover this disadvantage, this is where ","position":{"start":{"line":11,"column":124,"offset":688},"end":{"line":11,"column":348,"offset":912},"indent":[]}},{"type":"strong","children":[{"type":"text","value":"Attention","position":{"start":{"line":11,"column":350,"offset":914},"end":{"line":11,"column":359,"offset":923},"indent":[]}}],"position":{"start":{"line":11,"column":348,"offset":912},"end":{"line":11,"column":361,"offset":925},"indent":[]}},{"type":"text","value":" shines, and ","position":{"start":{"line":11,"column":361,"offset":925},"end":{"line":11,"column":374,"offset":938},"indent":[]}},{"type":"strong","children":[{"type":"text","value":"Transformer","position":{"start":{"line":11,"column":376,"offset":940},"end":{"line":11,"column":387,"offset":951},"indent":[]}}],"position":{"start":{"line":11,"column":374,"offset":938},"end":{"line":11,"column":389,"offset":953},"indent":[]}},{"type":"text","value":" model only uses this technique.","position":{"start":{"line":11,"column":389,"offset":953},"end":{"line":11,"column":421,"offset":985},"indent":[]}}],"position":{"start":{"line":10,"column":1,"offset":473},"end":{"line":11,"column":421,"offset":985},"indent":[1]}},{"type":"paragraph","children":[{"type":"html","value":"<br />","position":{"start":{"line":13,"column":1,"offset":987},"end":{"line":13,"column":7,"offset":993},"indent":[]}},{"type":"text","value":" ","position":{"start":{"line":13,"column":7,"offset":993},"end":{"line":13,"column":8,"offset":994},"indent":[]}},{"type":"strong","children":[{"type":"text","value":"Attention","position":{"start":{"line":13,"column":10,"offset":996},"end":{"line":13,"column":19,"offset":1005},"indent":[]}}],"position":{"start":{"line":13,"column":8,"offset":994},"end":{"line":13,"column":21,"offset":1007},"indent":[]}}],"position":{"start":{"line":13,"column":1,"offset":987},"end":{"line":13,"column":21,"offset":1007},"indent":[]}}],"position":{"start":{"line":1,"column":1,"offset":0},"end":{"line":14,"column":1,"offset":1008}}}}