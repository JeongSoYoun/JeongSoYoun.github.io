{"expireTime":9007200906040552000,"key":"transformer-remark-markdown-ast-3290249d2d3d7e036bc833655ac89a55-gatsby-remark-katexgatsby-remark-imagesgatsby-remark-images-medium-zoomgatsby-remark-responsive-iframegatsby-remark-prismjsgatsby-remark-copy-linked-filesgatsby-remark-smartypantsgatsby-remark-autolink-headersgatsby-remark-emoji-","val":{"type":"root","children":[{"type":"blockquote","children":[{"type":"heading","depth":3,"children":[{"type":"link","url":"#introduction","title":null,"children":[],"data":{"hProperties":{"aria-label":"introduction permalink","class":"anchor before"},"hChildren":[{"type":"raw","value":"<svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg>"}]}},{"type":"text","value":"Introduction","position":{"start":{"line":2,"column":7,"offset":7},"end":{"line":2,"column":19,"offset":19},"indent":[]}}],"position":{"start":{"line":2,"column":3,"offset":3},"end":{"line":2,"column":19,"offset":19},"indent":[]},"data":{"id":"introduction","htmlAttributes":{"id":"introduction"},"hProperties":{"id":"introduction","style":"position:relative;"}}},{"type":"paragraph","children":[{"type":"text","value":"From Transformer model with ","position":{"start":{"line":4,"column":3,"offset":24},"end":{"line":4,"column":31,"offset":52},"indent":[]}},{"type":"emphasis","children":[{"type":"text","value":"attention","position":{"start":{"line":4,"column":32,"offset":53},"end":{"line":4,"column":41,"offset":62},"indent":[]}}],"position":{"start":{"line":4,"column":31,"offset":52},"end":{"line":4,"column":42,"offset":63},"indent":[]}},{"type":"text","value":" , we have seen that NLP task can be done without RNN architecture, which has brought phenomenal development for NLP. This model has become fundamental architecture for NLP models such as BERT and GPT, which are two top tier NLP model nowadays. Today, I am going to talk about ","position":{"start":{"line":4,"column":42,"offset":63},"end":{"line":4,"column":319,"offset":340},"indent":[]}},{"type":"strong","children":[{"type":"emphasis","children":[{"type":"text","value":"GPT","position":{"start":{"line":4,"column":322,"offset":343},"end":{"line":4,"column":325,"offset":346},"indent":[]}}],"position":{"start":{"line":4,"column":321,"offset":342},"end":{"line":4,"column":326,"offset":347},"indent":[]}}],"position":{"start":{"line":4,"column":319,"offset":340},"end":{"line":4,"column":328,"offset":349},"indent":[]}},{"type":"text","value":" model.","position":{"start":{"line":4,"column":328,"offset":349},"end":{"line":4,"column":335,"offset":356},"indent":[]}}],"position":{"start":{"line":4,"column":3,"offset":24},"end":{"line":4,"column":335,"offset":356},"indent":[]}}],"position":{"start":{"line":2,"column":1,"offset":1},"end":{"line":4,"column":335,"offset":356},"indent":[1,1]}},{"type":"paragraph","children":[{"type":"html","value":"<br />","position":{"start":{"line":6,"column":1,"offset":358},"end":{"line":6,"column":7,"offset":364},"indent":[]}},{"type":"text","value":" ","position":{"start":{"line":6,"column":7,"offset":364},"end":{"line":6,"column":8,"offset":365},"indent":[]}},{"type":"text","value":" ","position":{"start":{"line":6,"column":8,"offset":365},"end":{"line":6,"column":14,"offset":371},"indent":[]}},{"type":"text","value":" ","position":{"start":{"line":6,"column":14,"offset":371},"end":{"line":6,"column":20,"offset":377},"indent":[]}},{"type":"text","value":" ","position":{"start":{"line":6,"column":20,"offset":377},"end":{"line":6,"column":26,"offset":383},"indent":[]}},{"type":"text","value":" ","position":{"start":{"line":6,"column":26,"offset":383},"end":{"line":6,"column":32,"offset":389},"indent":[]}},{"type":"text","value":" ","position":{"start":{"line":6,"column":32,"offset":389},"end":{"line":6,"column":38,"offset":395},"indent":[]}},{"type":"text","value":" GPT, ","position":{"start":{"line":6,"column":38,"offset":395},"end":{"line":6,"column":44,"offset":401},"indent":[]}},{"type":"emphasis","children":[{"type":"text","value":"Generative Pre Training","position":{"start":{"line":6,"column":45,"offset":402},"end":{"line":6,"column":68,"offset":425},"indent":[]}}],"position":{"start":{"line":6,"column":44,"offset":401},"end":{"line":6,"column":69,"offset":426},"indent":[]}},{"type":"text","value":", is a language model developed by ","position":{"start":{"line":6,"column":69,"offset":426},"end":{"line":6,"column":104,"offset":461},"indent":[]}},{"type":"strong","children":[{"type":"text","value":"Open AI","position":{"start":{"line":6,"column":106,"offset":463},"end":{"line":6,"column":113,"offset":470},"indent":[]}}],"position":{"start":{"line":6,"column":104,"offset":461},"end":{"line":6,"column":115,"offset":472},"indent":[]}},{"type":"text","value":" with combination of generative pre-training and discriminative fine-tuning process. The goal of GPT is making a general language model(pre-training) that can be adapted to lots of tasks with small adjustment of the model(fine-tuning).","position":{"start":{"line":6,"column":115,"offset":472},"end":{"line":6,"column":350,"offset":707},"indent":[]}}],"position":{"start":{"line":6,"column":1,"offset":358},"end":{"line":6,"column":350,"offset":707},"indent":[]}},{"type":"html","value":"<br />","position":{"start":{"line":8,"column":1,"offset":709},"end":{"line":8,"column":7,"offset":715},"indent":[]}},{"type":"blockquote","children":[{"type":"heading","depth":3,"children":[{"type":"link","url":"#trainig-process","title":null,"children":[],"data":{"hProperties":{"aria-label":"trainig process permalink","class":"anchor before"},"hChildren":[{"type":"raw","value":"<svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg>"}]}},{"type":"text","value":"Trainig Process","position":{"start":{"line":10,"column":7,"offset":723},"end":{"line":10,"column":22,"offset":738},"indent":[]}}],"position":{"start":{"line":10,"column":3,"offset":719},"end":{"line":10,"column":22,"offset":738},"indent":[]},"data":{"id":"trainig-process","htmlAttributes":{"id":"trainig-process"},"hProperties":{"id":"trainig-process","style":"position:relative;"}}},{"type":"paragraph","children":[{"type":"text","value":"From pre-training to fine-tuning","position":{"start":{"line":12,"column":3,"offset":743},"end":{"line":12,"column":35,"offset":775},"indent":[]}}],"position":{"start":{"line":12,"column":3,"offset":743},"end":{"line":12,"column":35,"offset":775},"indent":[]}}],"position":{"start":{"line":10,"column":1,"offset":717},"end":{"line":12,"column":35,"offset":775},"indent":[1,1]}},{"type":"paragraph","children":[{"type":"html","value":"<br />","position":{"start":{"line":14,"column":1,"offset":777},"end":{"line":14,"column":7,"offset":783},"indent":[]}},{"type":"text","value":" ","position":{"start":{"line":14,"column":7,"offset":783},"end":{"line":14,"column":8,"offset":784},"indent":[]}},{"type":"text","value":" ","position":{"start":{"line":14,"column":8,"offset":784},"end":{"line":14,"column":14,"offset":790},"indent":[]}},{"type":"text","value":" ","position":{"start":{"line":14,"column":14,"offset":790},"end":{"line":14,"column":20,"offset":796},"indent":[]}},{"type":"text","value":" ","position":{"start":{"line":14,"column":20,"offset":796},"end":{"line":14,"column":26,"offset":802},"indent":[]}},{"type":"text","value":" ","position":{"start":{"line":14,"column":26,"offset":802},"end":{"line":14,"column":32,"offset":808},"indent":[]}},{"type":"text","value":" ","position":{"start":{"line":14,"column":32,"offset":808},"end":{"line":14,"column":38,"offset":814},"indent":[]}},{"type":"text","value":" First, pre-training(unsupervised learning with set of large-corpus of text data) is done to learn the parameters of language model. Since, the goal of unsupervised learning is to initialize the training, the objectives of learning remain same with supervised learning. After pre-training, supervised learning with same parameters that have pre-trained is processed with fine-tuning of some change of input tokens and the weight of the output layer.","position":{"start":{"line":14,"column":38,"offset":814},"end":{"line":14,"column":487,"offset":1263},"indent":[]}}],"position":{"start":{"line":14,"column":1,"offset":777},"end":{"line":14,"column":487,"offset":1263},"indent":[]}},{"type":"html","value":"<br />","position":{"start":{"line":16,"column":1,"offset":1265},"end":{"line":16,"column":7,"offset":1271},"indent":[]}},{"type":"blockquote","children":[{"type":"heading","depth":3,"children":[{"type":"link","url":"#architecture","title":null,"children":[],"data":{"hProperties":{"aria-label":"architecture permalink","class":"anchor before"},"hChildren":[{"type":"raw","value":"<svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg>"}]}},{"type":"text","value":"Architecture","position":{"start":{"line":18,"column":7,"offset":1279},"end":{"line":18,"column":19,"offset":1291},"indent":[]}}],"position":{"start":{"line":18,"column":3,"offset":1275},"end":{"line":18,"column":19,"offset":1291},"indent":[]},"data":{"id":"architecture","htmlAttributes":{"id":"architecture"},"hProperties":{"id":"architecture","style":"position:relative;"}}}],"position":{"start":{"line":18,"column":1,"offset":1273},"end":{"line":18,"column":19,"offset":1291},"indent":[]}}],"position":{"start":{"line":1,"column":1,"offset":0},"end":{"line":19,"column":1,"offset":1292}}}}