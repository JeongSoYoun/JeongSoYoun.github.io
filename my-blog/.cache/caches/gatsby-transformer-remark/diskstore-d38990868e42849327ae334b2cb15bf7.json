{"expireTime":9007200905721960000,"key":"transformer-remark-markdown-ast-aa16a5a5e995d652de86b013f760efe3-gatsby-remark-katexgatsby-remark-imagesgatsby-remark-images-medium-zoomgatsby-remark-responsive-iframegatsby-remark-prismjsgatsby-remark-copy-linked-filesgatsby-remark-smartypantsgatsby-remark-autolink-headersgatsby-remark-emoji-","val":{"type":"root","children":[{"type":"html","value":"<img src=\"/assets/blog/google_ai.png\"  width=\"200\" height=\"200\">","position":{"start":{"line":2,"column":1,"offset":1},"end":{"line":2,"column":65,"offset":65},"indent":[]}},{"type":"blockquote","children":[{"type":"heading","depth":3,"children":[{"type":"link","url":"#transformer-model-attention-is-all-you-need","title":null,"children":[],"data":{"hProperties":{"aria-label":"transformer model attention is all you need permalink","class":"anchor before"},"hChildren":[{"type":"raw","value":"<svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg>"}]}},{"type":"emphasis","children":[{"type":"text","value":"Transformer Model: Attention is all you Need","position":{"start":{"line":4,"column":8,"offset":74},"end":{"line":4,"column":52,"offset":118},"indent":[]}}],"position":{"start":{"line":4,"column":7,"offset":73},"end":{"line":4,"column":53,"offset":119},"indent":[]}}],"position":{"start":{"line":4,"column":3,"offset":69},"end":{"line":4,"column":53,"offset":119},"indent":[]},"data":{"id":"transformer-model-attention-is-all-you-need","htmlAttributes":{"id":"transformer-model-attention-is-all-you-need"},"hProperties":{"id":"transformer-model-attention-is-all-you-need","style":"position:relative;"}}}],"position":{"start":{"line":4,"column":1,"offset":67},"end":{"line":4,"column":53,"offset":119},"indent":[]}},{"type":"paragraph","children":[{"type":"html","value":"<br />","position":{"start":{"line":6,"column":1,"offset":121},"end":{"line":6,"column":7,"offset":127},"indent":[]}},{"type":"text","value":"Transformer model was published by ","position":{"start":{"line":6,"column":7,"offset":127},"end":{"line":6,"column":42,"offset":162},"indent":[]}},{"type":"strong","children":[{"type":"text","value":"Google AI","position":{"start":{"line":6,"column":44,"offset":164},"end":{"line":6,"column":53,"offset":173},"indent":[]}}],"position":{"start":{"line":6,"column":42,"offset":162},"end":{"line":6,"column":55,"offset":175},"indent":[]}},{"type":"text","value":" on 2017, and became fundamental of Natural Language Process Model for the other models such as ","position":{"start":{"line":6,"column":55,"offset":175},"end":{"line":6,"column":151,"offset":271},"indent":[]}},{"type":"emphasis","children":[{"type":"text","value":"BERT","position":{"start":{"line":6,"column":152,"offset":272},"end":{"line":6,"column":156,"offset":276},"indent":[]}}],"position":{"start":{"line":6,"column":151,"offset":271},"end":{"line":6,"column":157,"offset":277},"indent":[]}},{"type":"text","value":" or ","position":{"start":{"line":6,"column":157,"offset":277},"end":{"line":6,"column":161,"offset":281},"indent":[]}},{"type":"emphasis","children":[{"type":"text","value":"GPT","position":{"start":{"line":6,"column":162,"offset":282},"end":{"line":6,"column":165,"offset":285},"indent":[]}}],"position":{"start":{"line":6,"column":161,"offset":281},"end":{"line":6,"column":166,"offset":286},"indent":[]}},{"type":"text","value":". What makes Transformer model attractive is, this model never uses ","position":{"start":{"line":6,"column":166,"offset":286},"end":{"line":6,"column":234,"offset":354},"indent":[]}},{"type":"strong","children":[{"type":"text","value":"RNN","position":{"start":{"line":6,"column":236,"offset":356},"end":{"line":6,"column":239,"offset":359},"indent":[]}}],"position":{"start":{"line":6,"column":234,"offset":354},"end":{"line":6,"column":241,"offset":361},"indent":[]}},{"type":"text","value":" architecture. It only uses ","position":{"start":{"line":6,"column":241,"offset":361},"end":{"line":6,"column":269,"offset":389},"indent":[]}},{"type":"strong","children":[{"type":"text","value":"Attention","position":{"start":{"line":6,"column":271,"offset":391},"end":{"line":6,"column":280,"offset":400},"indent":[]}}],"position":{"start":{"line":6,"column":269,"offset":389},"end":{"line":6,"column":282,"offset":402},"indent":[]}},{"type":"text","value":".","position":{"start":{"line":6,"column":282,"offset":402},"end":{"line":6,"column":283,"offset":403},"indent":[]}}],"position":{"start":{"line":6,"column":1,"offset":121},"end":{"line":6,"column":283,"offset":403},"indent":[]}},{"type":"paragraph","children":[{"type":"html","value":"<br/>","position":{"start":{"line":8,"column":1,"offset":405},"end":{"line":8,"column":6,"offset":410},"indent":[]}},{"type":"text","value":"Our language has some meaningful connection between words, which we called ","position":{"start":{"line":8,"column":6,"offset":410},"end":{"line":8,"column":81,"offset":485},"indent":[]}},{"type":"emphasis","children":[{"type":"text","value":"context","position":{"start":{"line":8,"column":82,"offset":486},"end":{"line":8,"column":89,"offset":493},"indent":[]}}],"position":{"start":{"line":8,"column":81,"offset":485},"end":{"line":8,"column":90,"offset":494},"indent":[]}},{"type":"text","value":".","position":{"start":{"line":8,"column":90,"offset":494},"end":{"line":8,"column":91,"offset":495},"indent":[]}}],"position":{"start":{"line":8,"column":1,"offset":405},"end":{"line":8,"column":91,"offset":495},"indent":[]}}],"position":{"start":{"line":1,"column":1,"offset":0},"end":{"line":9,"column":1,"offset":496}}}}