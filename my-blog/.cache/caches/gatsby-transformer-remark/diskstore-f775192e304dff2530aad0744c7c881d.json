{"expireTime":9007200906039246000,"key":"transformer-remark-markdown-html-b050f0c56a7fbb964af3afdaff3090a1-gatsby-remark-katexgatsby-remark-imagesgatsby-remark-images-medium-zoomgatsby-remark-responsive-iframegatsby-remark-prismjsgatsby-remark-copy-linked-filesgatsby-remark-smartypantsgatsby-remark-autolink-headersgatsby-remark-emoji-","val":"<p>From Transformer model with <em>attention</em> , we have seen that NLP task can be done without RNN architecture, which has brought phenomenal development for NLP. However, still we have to label our text input data, which takes lots of time</p>"}