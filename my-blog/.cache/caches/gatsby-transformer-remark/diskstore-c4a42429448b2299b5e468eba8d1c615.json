{"expireTime":9007200905722013000,"key":"transformer-remark-markdown-ast-449066ebed1510725885f24d339de323-gatsby-remark-katexgatsby-remark-imagesgatsby-remark-images-medium-zoomgatsby-remark-responsive-iframegatsby-remark-prismjsgatsby-remark-copy-linked-filesgatsby-remark-smartypantsgatsby-remark-autolink-headersgatsby-remark-emoji-","val":{"type":"root","children":[{"type":"html","value":"<img src=\"/assets/thumbnail/google_ai.png\"  width=\"200\" height=\"200\">","position":{"start":{"line":2,"column":1,"offset":1},"end":{"line":2,"column":70,"offset":70},"indent":[]}},{"type":"blockquote","children":[{"type":"heading","depth":3,"children":[{"type":"link","url":"#transformer-model-attention-is-all-you-need","title":null,"children":[],"data":{"hProperties":{"aria-label":"transformer model attention is all you need permalink","class":"anchor before"},"hChildren":[{"type":"raw","value":"<svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg>"}]}},{"type":"emphasis","children":[{"type":"text","value":"Transformer Model: Attention is all you Need","position":{"start":{"line":4,"column":8,"offset":79},"end":{"line":4,"column":52,"offset":123},"indent":[]}}],"position":{"start":{"line":4,"column":7,"offset":78},"end":{"line":4,"column":53,"offset":124},"indent":[]}}],"position":{"start":{"line":4,"column":3,"offset":74},"end":{"line":4,"column":53,"offset":124},"indent":[]},"data":{"id":"transformer-model-attention-is-all-you-need","htmlAttributes":{"id":"transformer-model-attention-is-all-you-need"},"hProperties":{"id":"transformer-model-attention-is-all-you-need","style":"position:relative;"}}}],"position":{"start":{"line":4,"column":1,"offset":72},"end":{"line":4,"column":53,"offset":124},"indent":[]}},{"type":"paragraph","children":[{"type":"html","value":"<br />","position":{"start":{"line":6,"column":1,"offset":126},"end":{"line":6,"column":7,"offset":132},"indent":[]}},{"type":"text","value":"Transformer model was published by ","position":{"start":{"line":6,"column":7,"offset":132},"end":{"line":6,"column":42,"offset":167},"indent":[]}},{"type":"strong","children":[{"type":"text","value":"Google AI","position":{"start":{"line":6,"column":44,"offset":169},"end":{"line":6,"column":53,"offset":178},"indent":[]}}],"position":{"start":{"line":6,"column":42,"offset":167},"end":{"line":6,"column":55,"offset":180},"indent":[]}},{"type":"text","value":" on 2017, and became fundamental of Natural Language Process Model for the other models such as ","position":{"start":{"line":6,"column":55,"offset":180},"end":{"line":6,"column":151,"offset":276},"indent":[]}},{"type":"emphasis","children":[{"type":"text","value":"BERT","position":{"start":{"line":6,"column":152,"offset":277},"end":{"line":6,"column":156,"offset":281},"indent":[]}}],"position":{"start":{"line":6,"column":151,"offset":276},"end":{"line":6,"column":157,"offset":282},"indent":[]}},{"type":"text","value":" or ","position":{"start":{"line":6,"column":157,"offset":282},"end":{"line":6,"column":161,"offset":286},"indent":[]}},{"type":"emphasis","children":[{"type":"text","value":"GPT","position":{"start":{"line":6,"column":162,"offset":287},"end":{"line":6,"column":165,"offset":290},"indent":[]}}],"position":{"start":{"line":6,"column":161,"offset":286},"end":{"line":6,"column":166,"offset":291},"indent":[]}},{"type":"text","value":". What makes Transformer model attractive is, this model never uses ","position":{"start":{"line":6,"column":166,"offset":291},"end":{"line":6,"column":234,"offset":359},"indent":[]}},{"type":"strong","children":[{"type":"text","value":"RNN","position":{"start":{"line":6,"column":236,"offset":361},"end":{"line":6,"column":239,"offset":364},"indent":[]}}],"position":{"start":{"line":6,"column":234,"offset":359},"end":{"line":6,"column":241,"offset":366},"indent":[]}},{"type":"text","value":" architecture. It only uses ","position":{"start":{"line":6,"column":241,"offset":366},"end":{"line":6,"column":269,"offset":394},"indent":[]}},{"type":"strong","children":[{"type":"text","value":"Attention","position":{"start":{"line":6,"column":271,"offset":396},"end":{"line":6,"column":280,"offset":405},"indent":[]}}],"position":{"start":{"line":6,"column":269,"offset":394},"end":{"line":6,"column":282,"offset":407},"indent":[]}},{"type":"text","value":".","position":{"start":{"line":6,"column":282,"offset":407},"end":{"line":6,"column":283,"offset":408},"indent":[]}}],"position":{"start":{"line":6,"column":1,"offset":126},"end":{"line":6,"column":283,"offset":408},"indent":[]}},{"type":"paragraph","children":[{"type":"html","value":"<br/>","position":{"start":{"line":8,"column":1,"offset":410},"end":{"line":8,"column":6,"offset":415},"indent":[]}},{"type":"text","value":"Our language has some meaningful connection between words, which we called ","position":{"start":{"line":8,"column":6,"offset":415},"end":{"line":8,"column":81,"offset":490},"indent":[]}},{"type":"emphasis","children":[{"type":"text","value":"context","position":{"start":{"line":8,"column":82,"offset":491},"end":{"line":8,"column":89,"offset":498},"indent":[]}}],"position":{"start":{"line":8,"column":81,"offset":490},"end":{"line":8,"column":90,"offset":499},"indent":[]}},{"type":"text","value":".","position":{"start":{"line":8,"column":90,"offset":499},"end":{"line":8,"column":91,"offset":500},"indent":[]}}],"position":{"start":{"line":8,"column":1,"offset":410},"end":{"line":8,"column":91,"offset":500},"indent":[]}}],"position":{"start":{"line":1,"column":1,"offset":0},"end":{"line":9,"column":1,"offset":501}}}}