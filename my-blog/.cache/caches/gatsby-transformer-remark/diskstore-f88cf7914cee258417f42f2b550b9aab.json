{"expireTime":9007200905724156000,"key":"transformer-remark-markdown-ast-41049c89576d675741bd265dc8f4a8b4-gatsby-remark-katexgatsby-remark-imagesgatsby-remark-images-medium-zoomgatsby-remark-responsive-iframegatsby-remark-prismjsgatsby-remark-copy-linked-filesgatsby-remark-smartypantsgatsby-remark-autolink-headersgatsby-remark-emoji-","val":{"type":"root","children":[{"type":"paragraph","children":[{"type":"image","title":null,"url":"/assets/blog/google.png","alt":"Tux, the Linux mascot","position":{"start":{"line":2,"column":1,"offset":1},"end":{"line":2,"column":50,"offset":50},"indent":[]}}],"position":{"start":{"line":2,"column":1,"offset":1},"end":{"line":2,"column":50,"offset":50},"indent":[]}},{"type":"blockquote","children":[{"type":"heading","depth":3,"children":[{"type":"link","url":"#transformer-model-attention-is-all-you-need","title":null,"children":[],"data":{"hProperties":{"aria-label":"transformer model attention is all you need permalink","class":"anchor before"},"hChildren":[{"type":"raw","value":"<svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg>"}]}},{"type":"emphasis","children":[{"type":"text","value":"Transformer Model: Attention is all you Need","position":{"start":{"line":4,"column":8,"offset":59},"end":{"line":4,"column":52,"offset":103},"indent":[]}}],"position":{"start":{"line":4,"column":7,"offset":58},"end":{"line":4,"column":53,"offset":104},"indent":[]}}],"position":{"start":{"line":4,"column":3,"offset":54},"end":{"line":4,"column":53,"offset":104},"indent":[]},"data":{"id":"transformer-model-attention-is-all-you-need","htmlAttributes":{"id":"transformer-model-attention-is-all-you-need"},"hProperties":{"id":"transformer-model-attention-is-all-you-need","style":"position:relative;"}}}],"position":{"start":{"line":4,"column":1,"offset":52},"end":{"line":4,"column":53,"offset":104},"indent":[]}},{"type":"paragraph","children":[{"type":"html","value":"<br />","position":{"start":{"line":6,"column":1,"offset":106},"end":{"line":6,"column":7,"offset":112},"indent":[]}},{"type":"text","value":"Transformer model was published by ","position":{"start":{"line":6,"column":7,"offset":112},"end":{"line":6,"column":42,"offset":147},"indent":[]}},{"type":"strong","children":[{"type":"text","value":"Google AI","position":{"start":{"line":6,"column":44,"offset":149},"end":{"line":6,"column":53,"offset":158},"indent":[]}}],"position":{"start":{"line":6,"column":42,"offset":147},"end":{"line":6,"column":55,"offset":160},"indent":[]}},{"type":"text","value":" on 2017, and became fundamental of Natural Language Process Model for the other models such as ","position":{"start":{"line":6,"column":55,"offset":160},"end":{"line":6,"column":151,"offset":256},"indent":[]}},{"type":"emphasis","children":[{"type":"text","value":"BERT","position":{"start":{"line":6,"column":152,"offset":257},"end":{"line":6,"column":156,"offset":261},"indent":[]}}],"position":{"start":{"line":6,"column":151,"offset":256},"end":{"line":6,"column":157,"offset":262},"indent":[]}},{"type":"text","value":" or ","position":{"start":{"line":6,"column":157,"offset":262},"end":{"line":6,"column":161,"offset":266},"indent":[]}},{"type":"emphasis","children":[{"type":"text","value":"GPT","position":{"start":{"line":6,"column":162,"offset":267},"end":{"line":6,"column":165,"offset":270},"indent":[]}}],"position":{"start":{"line":6,"column":161,"offset":266},"end":{"line":6,"column":166,"offset":271},"indent":[]}},{"type":"text","value":". What makes Transformer model attractive is, this model never uses ","position":{"start":{"line":6,"column":166,"offset":271},"end":{"line":6,"column":234,"offset":339},"indent":[]}},{"type":"strong","children":[{"type":"text","value":"RNN","position":{"start":{"line":6,"column":236,"offset":341},"end":{"line":6,"column":239,"offset":344},"indent":[]}}],"position":{"start":{"line":6,"column":234,"offset":339},"end":{"line":6,"column":241,"offset":346},"indent":[]}},{"type":"text","value":" architecture. It only uses ","position":{"start":{"line":6,"column":241,"offset":346},"end":{"line":6,"column":269,"offset":374},"indent":[]}},{"type":"strong","children":[{"type":"text","value":"Attention","position":{"start":{"line":6,"column":271,"offset":376},"end":{"line":6,"column":280,"offset":385},"indent":[]}}],"position":{"start":{"line":6,"column":269,"offset":374},"end":{"line":6,"column":282,"offset":387},"indent":[]}},{"type":"text","value":".","position":{"start":{"line":6,"column":282,"offset":387},"end":{"line":6,"column":283,"offset":388},"indent":[]}}],"position":{"start":{"line":6,"column":1,"offset":106},"end":{"line":6,"column":283,"offset":388},"indent":[]}},{"type":"paragraph","children":[{"type":"html","value":"<br/>","position":{"start":{"line":8,"column":1,"offset":390},"end":{"line":8,"column":6,"offset":395},"indent":[]}},{"type":"text","value":"Our language has some meaningful connection between words, which we called ","position":{"start":{"line":8,"column":6,"offset":395},"end":{"line":8,"column":81,"offset":470},"indent":[]}},{"type":"emphasis","children":[{"type":"text","value":"context","position":{"start":{"line":8,"column":82,"offset":471},"end":{"line":8,"column":89,"offset":478},"indent":[]}}],"position":{"start":{"line":8,"column":81,"offset":470},"end":{"line":8,"column":90,"offset":479},"indent":[]}},{"type":"text","value":".","position":{"start":{"line":8,"column":90,"offset":479},"end":{"line":8,"column":91,"offset":480},"indent":[]}}],"position":{"start":{"line":8,"column":1,"offset":390},"end":{"line":8,"column":91,"offset":480},"indent":[]}}],"position":{"start":{"line":1,"column":1,"offset":0},"end":{"line":9,"column":1,"offset":481}}}}