{"expireTime":9007200905812030000,"key":"transformer-remark-markdown-html-ast-942b0cd17729219d7d7949d8fa391cd3-gatsby-remark-katexgatsby-remark-imagesgatsby-remark-images-medium-zoomgatsby-remark-responsive-iframegatsby-remark-prismjsgatsby-remark-copy-linked-filesgatsby-remark-smartypantsgatsby-remark-autolink-headersgatsby-remark-emoji-","val":{"type":"root","children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"raw","value":"<br />","position":{"start":{"line":2,"column":1,"offset":1},"end":{"line":2,"column":7,"offset":7}}},{"type":"raw","value":"<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1200px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 52.66666666666667%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAAsTAAALEwEAmpwYAAAA+0lEQVQoz6WRX0/CMBTF+f5fQh/gnSiDESHCg9FgjAlGJeFPhKVra2xj1rK1dm3tcOjCQAKcNGlzkt/tvedW7Amq5LcxxmbnKDgvkdFmXW1Dv2YJ/pKCz5dqmTexWxuwkdrGIaWgWX+eMG6HT8P5IkgSEceJE2NsNnvjnGutx5MpRFgI8Qcn2kaLDxq2a4/TAPDB/aB73b/0Wn670/KvGp5/dl6tX3ghRM65ub1j7odVCxmcWqto9In6DyBwLsIYAIjxO0QIQtTp9l5eR4SQKGJSSkJomqalwLSw29JWSm0duLiqFb6O1I33E6x7FJMvB1ZY1L54/93zgfoGgyp+WM2mC3AAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"google\" title=\"google\" src=\"/static/fbc6dd92a8903039c6d1223bd49971b7/c1b63/google.png\" srcset=\"/static/fbc6dd92a8903039c6d1223bd49971b7/5a46d/google.png 300w,\n/static/fbc6dd92a8903039c6d1223bd49971b7/0a47e/google.png 600w,\n/static/fbc6dd92a8903039c6d1223bd49971b7/c1b63/google.png 1200w\" sizes=\"(max-width: 1200px) 100vw, 1200px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n    </span>","position":{"start":{"line":2,"column":7,"offset":7},"end":{"line":2,"column":63,"offset":63}}}],"position":{"start":{"line":2,"column":1,"offset":1},"end":{"line":2,"column":63,"offset":63}}},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{"id":"introduction","style":"position:relative;"},"children":[{"type":"element","tagName":"a","properties":{"href":"#introduction","aria-label":"introduction permalink","class":"anchor before"},"children":[{"type":"raw","value":"<svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg>"}]},{"type":"text","value":"Introduction","position":{"start":{"line":4,"column":4,"offset":68},"end":{"line":4,"column":16,"offset":80}}}],"position":{"start":{"line":4,"column":1,"offset":65},"end":{"line":4,"column":16,"offset":80}}},{"type":"text","value":"\n"},{"type":"raw","value":"<br />","position":{"start":{"line":6,"column":1,"offset":82},"end":{"line":6,"column":7,"offset":88}}},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{"id":"transformer-model-attention-is-all-you-need","style":"position:relative;"},"children":[{"type":"element","tagName":"a","properties":{"href":"#transformer-model-attention-is-all-you-need","aria-label":"transformer model attention is all you need permalink","class":"anchor before"},"children":[{"type":"raw","value":"<svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg>"}]},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"Transformer Model: Attention is all you Need","position":{"start":{"line":8,"column":8,"offset":97},"end":{"line":8,"column":52,"offset":141}}}],"position":{"start":{"line":8,"column":7,"offset":96},"end":{"line":8,"column":53,"offset":142}}}],"position":{"start":{"line":8,"column":3,"offset":92},"end":{"line":8,"column":53,"offset":142}}},{"type":"text","value":"\n"}],"position":{"start":{"line":8,"column":1,"offset":90},"end":{"line":8,"column":53,"offset":142}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"raw","value":"<br />","position":{"start":{"line":10,"column":1,"offset":144},"end":{"line":10,"column":7,"offset":150}}},{"type":"raw","value":"<br />","position":{"start":{"line":10,"column":7,"offset":150},"end":{"line":10,"column":13,"offset":156}}},{"type":"text","value":" ","position":{"start":{"line":10,"column":13,"offset":156},"end":{"line":10,"column":19,"offset":162}}},{"type":"text","value":" ","position":{"start":{"line":10,"column":19,"offset":162},"end":{"line":10,"column":25,"offset":168}}},{"type":"text","value":" ","position":{"start":{"line":10,"column":25,"offset":168},"end":{"line":10,"column":31,"offset":174}}},{"type":"text","value":" ","position":{"start":{"line":10,"column":31,"offset":174},"end":{"line":10,"column":37,"offset":180}}},{"type":"text","value":" ","position":{"start":{"line":10,"column":37,"offset":180},"end":{"line":10,"column":43,"offset":186}}},{"type":"text","value":"Transformer model was published by ","position":{"start":{"line":10,"column":43,"offset":186},"end":{"line":10,"column":78,"offset":221}}},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"Google AI","position":{"start":{"line":10,"column":80,"offset":223},"end":{"line":10,"column":89,"offset":232}}}],"position":{"start":{"line":10,"column":78,"offset":221},"end":{"line":10,"column":91,"offset":234}}},{"type":"text","value":" on 2017, and became fundamental of Natural Language Process Model for the other models such as ","position":{"start":{"line":10,"column":91,"offset":234},"end":{"line":10,"column":187,"offset":330}}},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"BERT","position":{"start":{"line":10,"column":188,"offset":331},"end":{"line":10,"column":192,"offset":335}}}],"position":{"start":{"line":10,"column":187,"offset":330},"end":{"line":10,"column":193,"offset":336}}},{"type":"text","value":" or ","position":{"start":{"line":10,"column":193,"offset":336},"end":{"line":10,"column":197,"offset":340}}},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"GPT","position":{"start":{"line":10,"column":198,"offset":341},"end":{"line":10,"column":201,"offset":344}}}],"position":{"start":{"line":10,"column":197,"offset":340},"end":{"line":10,"column":202,"offset":345}}},{"type":"text","value":". What makes Transformer model attractive is, this model never uses ","position":{"start":{"line":10,"column":202,"offset":345},"end":{"line":10,"column":270,"offset":413}}},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"RNN","position":{"start":{"line":10,"column":272,"offset":415},"end":{"line":10,"column":275,"offset":418}}}],"position":{"start":{"line":10,"column":270,"offset":413},"end":{"line":10,"column":277,"offset":420}}},{"type":"text","value":", one of the greatest sequence model, architecture. It only uses ","position":{"start":{"line":10,"column":277,"offset":420},"end":{"line":10,"column":342,"offset":485}}},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"Attention","position":{"start":{"line":10,"column":344,"offset":487},"end":{"line":10,"column":353,"offset":496}}}],"position":{"start":{"line":10,"column":342,"offset":485},"end":{"line":10,"column":355,"offset":498}}},{"type":"text","value":".","position":{"start":{"line":10,"column":355,"offset":498},"end":{"line":10,"column":356,"offset":499}}}],"position":{"start":{"line":10,"column":1,"offset":144},"end":{"line":10,"column":356,"offset":499}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"raw","value":"<br />","position":{"start":{"line":12,"column":1,"offset":501},"end":{"line":12,"column":7,"offset":507}}},{"type":"text","value":" ","position":{"start":{"line":12,"column":7,"offset":507},"end":{"line":12,"column":13,"offset":513}}},{"type":"text","value":" ","position":{"start":{"line":12,"column":13,"offset":513},"end":{"line":12,"column":19,"offset":519}}},{"type":"text","value":" ","position":{"start":{"line":12,"column":19,"offset":519},"end":{"line":12,"column":25,"offset":525}}},{"type":"text","value":" ","position":{"start":{"line":12,"column":25,"offset":525},"end":{"line":12,"column":31,"offset":531}}},{"type":"text","value":" ","position":{"start":{"line":12,"column":31,"offset":531},"end":{"line":12,"column":37,"offset":537}}},{"type":"text","value":"Our language has meaningful relationship in sentence, which we called ","position":{"start":{"line":12,"column":37,"offset":537},"end":{"line":12,"column":107,"offset":607}}},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"context","position":{"start":{"line":12,"column":108,"offset":608},"end":{"line":12,"column":115,"offset":615}}}],"position":{"start":{"line":12,"column":107,"offset":607},"end":{"line":12,"column":116,"offset":616}}},{"type":"text","value":". For human, we can easily guess what ","position":{"start":{"line":12,"column":116,"offset":616},"end":{"line":12,"column":154,"offset":654}}},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"it","position":{"start":{"line":12,"column":155,"offset":655},"end":{"line":12,"column":157,"offset":657}}}],"position":{"start":{"line":12,"column":154,"offset":654},"end":{"line":12,"column":158,"offset":658}}},{"type":"text","value":" stands for, but for machine learning points of view, it is hard to train what ","position":{"start":{"line":12,"column":158,"offset":658},"end":{"line":12,"column":237,"offset":737}}},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"it","position":{"start":{"line":12,"column":238,"offset":738},"end":{"line":12,"column":240,"offset":740}}}],"position":{"start":{"line":12,"column":237,"offset":737},"end":{"line":12,"column":241,"offset":741}}},{"type":"text","value":" means in the sentence. The biggest disadvantage of RNN is, this model only depends only short-term memory, so if our input text data set is large, performance of RNN is decreasing. To cover this disadvantage, this is where ","position":{"start":{"line":12,"column":241,"offset":741},"end":{"line":12,"column":465,"offset":965}}},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"Attention","position":{"start":{"line":12,"column":467,"offset":967},"end":{"line":12,"column":476,"offset":976}}}],"position":{"start":{"line":12,"column":465,"offset":965},"end":{"line":12,"column":478,"offset":978}}},{"type":"text","value":" shines, and ","position":{"start":{"line":12,"column":478,"offset":978},"end":{"line":12,"column":491,"offset":991}}},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"Transformer","position":{"start":{"line":12,"column":493,"offset":993},"end":{"line":12,"column":504,"offset":1004}}}],"position":{"start":{"line":12,"column":491,"offset":991},"end":{"line":12,"column":506,"offset":1006}}},{"type":"text","value":" model only uses this technique.","position":{"start":{"line":12,"column":506,"offset":1006},"end":{"line":12,"column":538,"offset":1038}}}],"position":{"start":{"line":12,"column":1,"offset":501},"end":{"line":12,"column":538,"offset":1038}}},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{"id":"architecture","style":"position:relative;"},"children":[{"type":"element","tagName":"a","properties":{"href":"#architecture","aria-label":"architecture permalink","class":"anchor before"},"children":[{"type":"raw","value":"<svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg>"}]},{"type":"text","value":"Architecture","position":{"start":{"line":14,"column":4,"offset":1043},"end":{"line":14,"column":16,"offset":1055}}}],"position":{"start":{"line":14,"column":1,"offset":1040},"end":{"line":14,"column":16,"offset":1055}}},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{"id":"input---encoder---deocder---output","style":"position:relative;"},"children":[{"type":"element","tagName":"a","properties":{"href":"#input---encoder---deocder---output","aria-label":"input   encoder   deocder   output permalink","class":"anchor before"},"children":[{"type":"raw","value":"<svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg>"}]},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"Input - Encoder - Deocder - Output","position":{"start":{"line":16,"column":8,"offset":1064},"end":{"line":16,"column":42,"offset":1098}}}],"position":{"start":{"line":16,"column":7,"offset":1063},"end":{"line":16,"column":43,"offset":1099}}}],"position":{"start":{"line":16,"column":3,"offset":1059},"end":{"line":16,"column":43,"offset":1099}}},{"type":"text","value":"\n"}],"position":{"start":{"line":16,"column":1,"offset":1057},"end":{"line":16,"column":43,"offset":1099}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":" ","position":{"start":{"line":18,"column":1,"offset":1101},"end":{"line":18,"column":7,"offset":1107}}},{"type":"text","value":" ","position":{"start":{"line":18,"column":7,"offset":1107},"end":{"line":18,"column":13,"offset":1113}}},{"type":"text","value":" ","position":{"start":{"line":18,"column":13,"offset":1113},"end":{"line":18,"column":19,"offset":1119}}},{"type":"text","value":" ","position":{"start":{"line":18,"column":19,"offset":1119},"end":{"line":18,"column":25,"offset":1125}}},{"type":"text","value":" ","position":{"start":{"line":18,"column":25,"offset":1125},"end":{"line":18,"column":31,"offset":1131}}},{"type":"text","value":" Transformer model consists of ","position":{"start":{"line":18,"column":31,"offset":1131},"end":{"line":18,"column":62,"offset":1162}}},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"Encoder","position":{"start":{"line":18,"column":63,"offset":1163},"end":{"line":18,"column":70,"offset":1170}}}],"position":{"start":{"line":18,"column":62,"offset":1162},"end":{"line":18,"column":71,"offset":1171}}},{"type":"text","value":" layer and ","position":{"start":{"line":18,"column":71,"offset":1171},"end":{"line":18,"column":82,"offset":1182}}},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"Decoder","position":{"start":{"line":18,"column":83,"offset":1183},"end":{"line":18,"column":90,"offset":1190}}}],"position":{"start":{"line":18,"column":82,"offset":1182},"end":{"line":18,"column":91,"offset":1191}}},{"type":"text","value":" layer, which is same architecture with ","position":{"start":{"line":18,"column":91,"offset":1191},"end":{"line":18,"column":131,"offset":1231}}},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"seq2seq","position":{"start":{"line":18,"column":133,"offset":1233},"end":{"line":18,"column":140,"offset":1240}}}],"position":{"start":{"line":18,"column":131,"offset":1231},"end":{"line":18,"column":142,"offset":1242}}},{"type":"text","value":" model, but the inside of each layer has ","position":{"start":{"line":18,"column":142,"offset":1242},"end":{"line":18,"column":183,"offset":1283}}},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"attention","position":{"start":{"line":18,"column":185,"offset":1285},"end":{"line":18,"column":194,"offset":1294}}}],"position":{"start":{"line":18,"column":183,"offset":1283},"end":{"line":18,"column":196,"offset":1296}}},{"type":"text","value":" layer not ","position":{"start":{"line":18,"column":196,"offset":1296},"end":{"line":18,"column":207,"offset":1307}}},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"RNN","position":{"start":{"line":18,"column":209,"offset":1309},"end":{"line":18,"column":212,"offset":1312}}}],"position":{"start":{"line":18,"column":207,"offset":1307},"end":{"line":18,"column":214,"offset":1314}}},{"type":"text","value":". The most important part of attention in Transforme model is ","position":{"start":{"line":18,"column":214,"offset":1314},"end":{"line":18,"column":276,"offset":1376}}},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"Self-Attention","position":{"start":{"line":18,"column":278,"offset":1378},"end":{"line":18,"column":292,"offset":1392}}}],"position":{"start":{"line":18,"column":276,"offset":1376},"end":{"line":18,"column":294,"offset":1394}}},{"type":"text","value":".","position":{"start":{"line":18,"column":294,"offset":1394},"end":{"line":18,"column":295,"offset":1395}}}],"position":{"start":{"line":18,"column":1,"offset":1101},"end":{"line":18,"column":295,"offset":1395}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"raw","value":"<br />","position":{"start":{"line":20,"column":1,"offset":1397},"end":{"line":20,"column":7,"offset":1403}}},{"type":"text","value":" Self-Attention directly makes Transformer model see relationships between all words in sentence and figured it out which word to attend importantly. This mechanism is done through ","position":{"start":{"line":20,"column":7,"offset":1403},"end":{"line":20,"column":188,"offset":1584}}},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"Encoder","position":{"start":{"line":20,"column":189,"offset":1585},"end":{"line":20,"column":196,"offset":1592}}}],"position":{"start":{"line":20,"column":188,"offset":1584},"end":{"line":20,"column":197,"offset":1593}}},{"type":"text","value":" and ","position":{"start":{"line":20,"column":197,"offset":1593},"end":{"line":20,"column":202,"offset":1598}}},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"Decoder","position":{"start":{"line":20,"column":203,"offset":1599},"end":{"line":20,"column":210,"offset":1606}}}],"position":{"start":{"line":20,"column":202,"offset":1598},"end":{"line":20,"column":211,"offset":1607}}},{"type":"text","value":" layers.","position":{"start":{"line":20,"column":211,"offset":1607},"end":{"line":20,"column":219,"offset":1615}}}],"position":{"start":{"line":20,"column":1,"offset":1397},"end":{"line":20,"column":219,"offset":1615}}},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{"id":"conclusion","style":"position:relative;"},"children":[{"type":"element","tagName":"a","properties":{"href":"#conclusion","aria-label":"conclusion permalink","class":"anchor before"},"children":[{"type":"raw","value":"<svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg>"}]},{"type":"text","value":"Conclusion","position":{"start":{"line":22,"column":4,"offset":1620},"end":{"line":22,"column":14,"offset":1630}}}],"position":{"start":{"line":22,"column":1,"offset":1617},"end":{"line":22,"column":14,"offset":1630}}},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":" ","position":{"start":{"line":24,"column":1,"offset":1632},"end":{"line":24,"column":7,"offset":1638}}},{"type":"text","value":" ","position":{"start":{"line":24,"column":7,"offset":1638},"end":{"line":24,"column":13,"offset":1644}}},{"type":"text","value":" ","position":{"start":{"line":24,"column":13,"offset":1644},"end":{"line":24,"column":19,"offset":1650}}},{"type":"text","value":" ","position":{"start":{"line":24,"column":19,"offset":1650},"end":{"line":24,"column":25,"offset":1656}}},{"type":"text","value":" ","position":{"start":{"line":24,"column":25,"offset":1656},"end":{"line":24,"column":31,"offset":1662}}},{"type":"text","value":"Transformer is beautiful!","position":{"start":{"line":24,"column":31,"offset":1662},"end":{"line":24,"column":56,"offset":1687}}}],"position":{"start":{"line":24,"column":1,"offset":1632},"end":{"line":24,"column":56,"offset":1687}}}],"position":{"start":{"line":1,"column":1,"offset":0},"end":{"line":25,"column":1,"offset":1688}}}}